{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T16:03:57.600527Z",
     "start_time": "2024-11-06T16:03:56.660256Z"
    }
   },
   "cell_type": "code",
   "source": "%pip install faiss-cpu",
   "id": "4b7ae0d21d0740ea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: faiss-cpu in ./venv/lib/python3.12/site-packages (1.9.0)\r\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in ./venv/lib/python3.12/site-packages (from faiss-cpu) (2.1.3)\r\n",
      "Requirement already satisfied: packaging in ./venv/lib/python3.12/site-packages (from faiss-cpu) (24.1)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "3851e7387623cc92",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-06T16:14:15.054316Z",
     "start_time": "2024-11-06T16:14:13.534771Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer, AutoModel, GPT2LMHeadModel\n",
    "import faiss\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from collections import OrderedDict"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T16:14:15.058298Z",
     "start_time": "2024-11-06T16:14:15.055313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "def read_text_files(directory_path: str) -> list[str]:\n",
    "\t\"\"\"\n",
    "\tReads all .txt files in the specified directory, stores each file's content as a single string,\n",
    "\tand appends it to a main list.\n",
    "\t\n",
    "\t:return: a list where each element is the content of a single text file.\n",
    "\t\"\"\"\n",
    "\tfile_contents = []\n",
    "\t\n",
    "\tfor filename in os.listdir(directory_path):\n",
    "\t\tif filename.endswith('.txt'):\n",
    "\t\t\tfile_path = os.path.join(directory_path, filename)\n",
    "\t\t\twith open(file_path, 'r', encoding='utf-8') as file:\n",
    "\t\t\t\tcontent = file.read()\n",
    "\t\t\t\tfile_contents.append(content)\n",
    "\t\n",
    "\treturn file_contents\n"
   ],
   "id": "4cbfa8be7e8cec02",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T16:14:15.072583Z",
     "start_time": "2024-11-06T16:14:15.059360Z"
    }
   },
   "cell_type": "code",
   "source": "text_chunks = read_text_files('data')",
   "id": "b69c7e0d7280d055",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T16:14:19.624006Z",
     "start_time": "2024-11-06T16:14:16.187376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# load embedding and generation models\n",
    "embedder = AutoModel.from_pretrained(\"gpt2\") # sentence-transformers/all-MiniLM-L6-v2\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "generator = GPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
    "\n",
    "def create_embeddings(text_chunks):\n",
    "\tchunk_embeddings = []\n",
    "\t\n",
    "\tfor i, chunk in enumerate(text_chunks):\n",
    "\t\t\n",
    "\n",
    "\t\t# tokenize with truncation\n",
    "\t\tinputs = tokenizer(chunk, return_tensors=\"pt\", truncation=True)\n",
    "\t\t\n",
    "\t\t# generate embeddings\n",
    "\t\twith torch.no_grad():\n",
    "\t\t\tembedding = embedder(**inputs).last_hidden_state.mean(dim=1)\n",
    "\t\tchunk_embeddings.append(embedding)\n",
    "\t\n",
    "\treturn chunk_embeddings\n",
    "\n",
    "embeddings = create_embeddings(text_chunks)"
   ],
   "id": "b2d422da7895a43b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T16:14:21.166931Z",
     "start_time": "2024-11-06T16:14:21.162634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set up FAISS\n",
    "dimension = embeddings[0].shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(np.vstack(embeddings))"
   ],
   "id": "56cfc99dc9b2bd05",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T16:14:22.321797Z",
     "start_time": "2024-11-06T16:14:22.317273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def gen_answer(query: str):\n",
    "\t\n",
    "\t# query workflow\n",
    "\tquery_embedding = embedder(**tokenizer(query, return_tensors=\"pt\")).last_hidden_state.mean(dim=1).detach().numpy()\n",
    "\tdistances, indices = index.search(query_embedding, k=3)  # retrieve top-k relevant chunks\n",
    "\ttokenizer.add_special_tokens({\"pad_token\": \"--\"})\n",
    "\tcontext = \" \".join([text_chunks[i] for i in indices[0]])\n",
    "\tinput_text = f\"Context: {context}\\n\\nQuery: {query}\\nAnswer:\"\n",
    "\tinputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\tattention_mask = inputs['attention_mask']\n",
    "\t\n",
    "\t# generate output with attention mask\n",
    "\toutput = generator.generate(inputs['input_ids'], attention_mask=attention_mask, max_length=1_000)\n",
    "\tanswer = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\tanswer = answer.split(sep='Answer: ')[1] # remove context\n",
    "\tprint(\"\\n\".join(list(OrderedDict.fromkeys(answer.split(\"\\n\"))))) # remove duplicate answers\n"
   ],
   "id": "779f26513d2da656",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "cbdfbb16871bd0da"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T16:14:33.490226Z",
     "start_time": "2024-11-06T16:14:24.044029Z"
    }
   },
   "cell_type": "code",
   "source": "gen_answer(\"How much money can i get from a canceled flight?\")",
   "id": "625bee93059796b2",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The airline will give you a written notice of the cancellation of your flight.\n",
      "\n",
      "If you are unable to get the airline to give you a written notice, you can request a refund of the amount you paid for the item.\n",
      "If you are unable to get the\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T16:14:38.665277Z",
     "start_time": "2024-11-06T16:14:33.491382Z"
    }
   },
   "cell_type": "code",
   "source": "gen_answer(\"How long must a flight be delayed before i get compensation?\")\n",
   "id": "eb2374b49659de7e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The airline must provide you with a choice between:\n",
      "\n",
      "    reimbursement of your ticket and, if you have a connecting flight, a return flight to the airport of departure at the earliest opportunity\n",
      "The airline must offer you, on a oneoff basis, a choice between:\n",
      "    the reimbursement of your ticket and, if you have a connecting flight, a return flight to the airport of departure at the earliest opportunity\n",
      "    the reimbursement of your ticket and, if you have a connecting flight,\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-06T16:04:32.896024Z",
     "start_time": "2024-11-06T16:04:32.893692Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4dd686798cab0fd9",
   "outputs": [],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
